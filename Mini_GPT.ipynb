{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7KyZI4oFQAvU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9bZ9vWMQVRA",
        "outputId": "5d8f1711-25c9-4c38-b117-83cb2eaa68a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIJ5klr3QbCO",
        "outputId": "b440c5d3-2300-4032-c98e-03f7239aa6c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e1ae4af99f0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1: Load & Tokenize Dataset (Shakespeare)"
      ],
      "metadata": {
        "id": "MbsIJJzAZZRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"\"\"\n",
        "To be, or not to be, that is the question:\n",
        "Whether 'tis nobler in the mind to suffer\n",
        "The slings and arrows of outrageous fortune,\n",
        "Or to take arms against a sea of troubles\n",
        "And by opposing end them.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "3Bj5nrFCQfSL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f\"Vocab size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrNT2mxvQoZd",
        "outputId": "956801ff-37e8-4f06-b68b-96995a3de743"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping from char to int\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itost = {i: ch for ch, i in stoi.items()}\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itost[i] for i in l])"
      ],
      "metadata": {
        "id": "hbS1x3hxRp3h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode dataset as integers\n",
        "data = torch.tensor(encode(text), dtype=torch.long)"
      ],
      "metadata": {
        "id": "ixR5w6zIRyDV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2: Dataset Preparation"
      ],
      "metadata": {
        "id": "UmhRjSm2ZW68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8  # sequence length\n",
        "\n",
        "\n",
        "def get_batch(split='train'):\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(data) - block_size):\n",
        "      x.append(data[i:i+block_size])\n",
        "      y.append(data[i+1:i+block_size+1])\n",
        "    return torch.stack(x), torch.stack(y)\n",
        "\n",
        "X, Y = get_batch()\n",
        "print(X.shape)\n",
        "print(\"Input:\", decode(X[0].tolist()))\n",
        "print(\"Target:\", decode(Y[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJUgIjmLRyE5",
        "outputId": "384521fd-13d3-4ca1-cc44-d1fefc8ec140"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([191, 8])\n",
            "Input: \n",
            "To be, \n",
            "Target: To be, o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3: Self-Attention Layer (1-head)"
      ],
      "metadata": {
        "id": "yabxeo4XZiET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, emb_size):\n",
        "    super().__init__() # Calling the constructor of the parent class so that all of its internal mechanisms (like parameter tracking, hooks, buffers, etc.) are properly initialized.\n",
        "    self.query = nn.Linear(emb_size, emb_size)\n",
        "    self.key = nn.Linear(emb_size, emb_size)\n",
        "    self.value = nn.Linear(emb_size, emb_size)\n",
        "    self.register_buffer(\"mask\", torch.tril(torch.ones(block_size, block_size))) # mask out future tokens in self-attention, enforcing that the model can’t \"cheat\" by looking ahead.\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape # B → Batch size: number of sequences in the batch; T → Sequence length (also called block_size in this notebook); C → Embedding dimension: how many features per token\n",
        "    q = self.query(x)  # (B,T,C)\n",
        "    k = self.key(x)\n",
        "    v = self.value(x)\n",
        "\n",
        "    attn_score = q@k.transpose(-2, -1)/math.sqrt(C) # Transpose(-2,-1) gives B,C,T. #BxCxC\n",
        "    attn_score = attn_score.masked_fill(self.mask[:T, :T] == 0, float('-inf')) # Masking upper triangle to prevent future look up\n",
        "    attn_score = F.softmax(attn_score, dim=-1)\n",
        "    return attn_score @ v\n",
        "\n"
      ],
      "metadata": {
        "id": "utVRrgN2ZTxO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4: Encoder only transformer"
      ],
      "metadata": {
        "id": "8YG38r6im_mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer_Block_EncoderOnly(nn.Module):\n",
        "  def __init__(self, emb_size):\n",
        "    super().__init__()\n",
        "    self.attn = SelfAttention(emb_size)\n",
        "    self.ff = nn.Sequential(\n",
        "        nn.Linear(emb_size, 2*emb_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(2*emb_size, emb_size)\n",
        "    )\n",
        "    self.ln = nn.LayerNorm(emb_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = self.ln(self.attn(x))\n",
        "    return self.ff(h)\n"
      ],
      "metadata": {
        "id": "3ye1RBLzjyTt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 5: Mini GPT"
      ],
      "metadata": {
        "id": "lPIMYGEom7OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Mini_GPT(nn.Module):\n",
        "  def __init__(self, vocab_size, emb_size, block_size):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, emb_size)\n",
        "    self.pos_embed = nn.Embedding(block_size, emb_size)\n",
        "    self.trans = nn.Sequential(\n",
        "        Transformer_Block_EncoderOnly(emb_size),\n",
        "        Transformer_Block_EncoderOnly(emb_size)\n",
        "    )\n",
        "    self.ln = nn.LayerNorm(emb_size)\n",
        "    self.logit_output = nn.Linear(emb_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx):\n",
        "    B, T = idx.shape\n",
        "    tok = self.embed(idx)\n",
        "    pos = self.pos_embed(torch.arange(T, device=idx.device))\n",
        "    x = tok + pos\n",
        "    h = self.trans(x)\n",
        "    return self.logit_output(self.ln(h))"
      ],
      "metadata": {
        "id": "XiNFqB_nk6wo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 6: Train Loop"
      ],
      "metadata": {
        "id": "TA-eA82bmr2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Mini_GPT(vocab_size=vocab_size, emb_size=64, block_size=block_size)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "sCZ89ERZmeok"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "  logits = model(X)\n",
        "  B, T, C = logits.shape\n",
        "  loss = loss_fn(logits.view(B*T, C), Y.view(B*T))\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 25 == 0:\n",
        "      print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeCsQw0Ink5y",
        "outputId": "eb9a05e0-7371-41c4-a02f-b7a9a487ecf2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 2.6639\n",
            "Epoch 25 | Loss: 1.7269\n",
            "Epoch 50 | Loss: 0.9452\n",
            "Epoch 75 | Loss: 0.5538\n",
            "Epoch 100 | Loss: 0.4200\n",
            "Epoch 125 | Loss: 0.3647\n",
            "Epoch 150 | Loss: 0.3378\n",
            "Epoch 175 | Loss: 0.3256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 7: Generate"
      ],
      "metadata": {
        "id": "navB48f5oycu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens):\n",
        "    model.eval()\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -block_size:]\n",
        "        logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "        idx = torch.cat((idx, next_token), dim=1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "VwdKcPA3oxOQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = torch.tensor([[stoi['T']]])\n",
        "output = generate(model, start, 100)\n",
        "print(\"\\nGenerated Text:\\n\", decode(output[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgeLFfOJpAY7",
        "outputId": "73bd77b3-50f9-434e-db1d-74f0415732d0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            " The r'tis nobler in the mind the mind to suffer\n",
            "The slings and arrows of outrageous fortune,\n",
            "Or to ta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's experiment using subword tokens"
      ],
      "metadata": {
        "id": "6zbHCViPpIjb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iTvvS7f6pPHf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}